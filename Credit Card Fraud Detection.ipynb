{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "  It is important that credit card companies are able to recognize frauds on credit card transactions.\n",
    "  \n",
    "   On Kaggle, we have access to a dataset which contains transactions made by credit cards in September 2013 by europeans. This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
    "   \n",
    "   The features V1, V2, ..., V28 are the principal components obtained with PCA and all are numeric and confidentials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset: \n",
    "\n",
    "https://www.kaggle.com/mlg-ulb/creditcardfraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "Due to the fraudulent credit card transactions problem and your data, how good we can predict them?\n",
    "\n",
    "To solve this problem, we'll follow a standard data science pipeline plan of attack:\n",
    "\n",
    "#### 1. Understand the problem and the data\n",
    "#### 2. Data exploration\n",
    "#### 3. Feature engineering / feature selection\n",
    "#### 4. Model evaluation and selection\n",
    "#### 5. Model optimization\n",
    "#### 6. Interpretation of results and predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Start:\n",
    "\n",
    "Doing the necessary imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's ignore warnings about deprecated things:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "card_transactions = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand the problem and the data\n",
    "\n",
    "I will start seeing the shape and columns names of our dataset, to answer my question: How many features and instances do I have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 31)\n",
      "---------------------------------------------------------------------------\n",
      "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
      "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
      "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
      "       'Class'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(card_transactions.shape)\n",
    "print('---------------------------------------------------------------------------')\n",
    "print(card_transactions.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned before, the features passed by a PCA algorithm and they are confidentials. The name doesn't help us to understand.\n",
    "\n",
    "Let's check all feature __types__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time      float64\n",
      "V1        float64\n",
      "V2        float64\n",
      "V3        float64\n",
      "V4        float64\n",
      "V5        float64\n",
      "V6        float64\n",
      "V7        float64\n",
      "V8        float64\n",
      "V9        float64\n",
      "V10       float64\n",
      "V11       float64\n",
      "V12       float64\n",
      "V13       float64\n",
      "V14       float64\n",
      "V15       float64\n",
      "V16       float64\n",
      "V17       float64\n",
      "V18       float64\n",
      "V19       float64\n",
      "V20       float64\n",
      "V21       float64\n",
      "V22       float64\n",
      "V23       float64\n",
      "V24       float64\n",
      "V25       float64\n",
      "V26       float64\n",
      "V27       float64\n",
      "V28       float64\n",
      "Amount    float64\n",
      "Class       int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(card_transactions.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of them are numerical and it's coherent. So doesn't need any type of cast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the Kaggle's challenge description of dataset, they tell this data have a unbalanced distribution. Let's check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Frequency')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "count_classes = pd.value_counts(card_transactions['Class'], sort = True)\n",
    "\n",
    "# Creating a plot with bar kind:\n",
    "count_classes.plot(kind = 'bar', rot=0)\n",
    "\n",
    "# Setting plotting title and axi's legends:\n",
    "plt.title(\"Data Class distribution\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'm sure, the data is totally unbalanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__There are several ways to approach this unbalanced distribution problem:__\n",
    "\n",
    "- Collect more data. (Not applicable in this case)\n",
    "***\n",
    "- Use metrics like F1, Precision, Recall and ROC\n",
    "    - __Here is a link for a very good post talking about metrics for unbalanced data: https://towardsdatascience.com/what-metrics-should-we-use-on-imbalanced-data-set-precision-recall-roc-e2e79252aeba__\n",
    "***\n",
    "- Resampling the dataset\n",
    "\n",
    "    - This is as method that will process the data to have an approximate 50-50 ratio;\n",
    "    \n",
    "    - One way to anchieve this is OVER-sampling, adding copies of the under-represented class (better with __little__ data);\n",
    "    \n",
    "    - Another way is UNDER-sampling, deleting instances from the over-represented class (better with __lot's__ of data).\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration / Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Have any null value in the DataFrame?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to check if have any value on instances with null values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(card_transactions.isnull().values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, I don't need to worry about treat null values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis Fraud and Valid Transactions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the number of fraud and valid transactions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud shape: (492, 31)\n",
      "Valid shape: (284315, 31)\n"
     ]
    }
   ],
   "source": [
    "fraud_data = card_transactions[card_transactions['Class'] == 1]\n",
    "normal_data = card_transactions[card_transactions['Class'] == 0]\n",
    "\n",
    "print('Fraud shape: ' + str(fraud_data.shape))\n",
    "print('Valid shape: ' + str(normal_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many percents each Class represents on this skewed distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Fraud:  0.17 % of the dataset.\n",
      "Fraud:  99.83 % of the dataset.\n"
     ]
    }
   ],
   "source": [
    "print('No Fraud: ', round(len(fraud_data)/len(card_transactions) * 100,2), '% of the dataset.')\n",
    "print('Fraud: ', round(len(normal_data)/len(card_transactions) * 100,2), '% of the dataset.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How different are the amount of money used in different transaction classes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normal transactions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     492.000000\n",
      "mean      122.211321\n",
      "std       256.683288\n",
      "min         0.000000\n",
      "25%         1.000000\n",
      "50%         9.250000\n",
      "75%       105.890000\n",
      "max      2125.870000\n",
      "Name: Amount, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(fraud_data.Amount.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fraud transactions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    284315.000000\n",
      "mean         88.291022\n",
      "std         250.105092\n",
      "min           0.000000\n",
      "25%           5.650000\n",
      "50%          22.000000\n",
      "75%          77.050000\n",
      "max       25691.160000\n",
      "Name: Amount, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(normal_data.Amount.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering / feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am not going to perform feature engineering or feature selection in first instance.\n",
    "\n",
    "The dataset already has been downgraded in order to contain 30 features (28 anonymous + time + amount). Acording to Kaggle's description, they used PCA as feature engineering to reduce number of features.\n",
    "\n",
    "The only thing I'm going to do is normalize the _Amount_. As we could see previously, have a lot of variantion on data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.244964\n",
      "1   -0.342475\n",
      "2    1.160686\n",
      "3    0.140534\n",
      "4   -0.073403\n",
      "Name: normAmount, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "amount_values = card_transactions['Amount'].values\n",
    "standardized_amount = StandardScaler().fit_transform(amount_values.reshape(-1, 1))\n",
    "card_transactions['normAmount'] = standardized_amount\n",
    "card_transactions = card_transactions.drop(['Time', 'Amount'], axis=1)\n",
    "print(card_transactions['normAmount'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation and selection\n",
    "\n",
    "### Approach:\n",
    "1. Select Classifiers Algorithms to be used.\n",
    "***\n",
    "2. Compare what happens when using resampling techniques and when not using it.\n",
    "    - Evaluate the models by using *_Stratified Cross Validation_ (for not resampled), normal Cross Validation (for resampled) and some of the performance metrics mentioned before.\n",
    "***\n",
    "3. Repeat the best resampling/not resampling method, by tuning the parameters.\n",
    "***\n",
    "\n",
    "*_Stratified Cross Validation_ is a recommended CV technique to large imbalance in the distribution of the target class which the folds are made by preserving the percentage of samples for each class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier Algorithms:\n",
    "\n",
    "I'm going to use these algorithms:\n",
    "\n",
    "* [Multi-layer Perceptron (MLPClassifier)](http://scikit-learn.org/stable/modules/neural_networks_supervised.html#multi-layer-perceptron)\n",
    "* [Random Forest Classifier (RandomForestClassifier)](http://scikit-learn.org/stable/modules/ensemble.html#random-forests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not resampling:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spliting data in X set and Y set (target): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = card_transactions.iloc[:, card_transactions.columns != 'Class']\n",
    "y = card_transactions.iloc[:, card_transactions.columns == 'Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to create a function to perform and evaluate the models.\n",
    "- As said before, going to use Stratified Cross Validation because the dataset distribution is imbalanced\n",
    "- Will evaluate models with metrics: F1 and ROC_AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This fuction will evaluate used models returning f1 and roc_auc scores averages \n",
    "# of Stratified Cross Validation folders.\n",
    "def evaluate_models(X, y):\n",
    "    # Creating dict to save scores to evaluate:\n",
    "    f1_scores['MLPClassifier'] = []\n",
    "    roc_scores['MLPClassifier'] = []\n",
    "    f1_scores['RandomForestClassifier'] = []\n",
    "    roc_scores['RandomForestClassifier'] = []\n",
    "\n",
    "    # Initializing Stratified Cross Validation:\n",
    "    sss = StratifiedShuffleSplit(n_splits=5, test_size=0.3, random_state=42)\n",
    "    count = 0\n",
    "    for train_index, test_index in sss.split(X, y):\n",
    "        count += 1\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        perform_models(\n",
    "            [\n",
    "                MLPClassifier(solver='lbfgs'),\n",
    "                RandomForestClassifier(n_estimators=100, n_jobs=-1),\n",
    "            ],\n",
    "            X_train, X_test,\n",
    "            y_train, y_test,\n",
    "            count\n",
    "        )\n",
    "    print('Results:')\n",
    "    for model in f1_scores.keys():\n",
    "        print('  ' + model + ' has f1 average: ' + str( sum(f1_scores[model]) / len(f1_scores[model]) ))\n",
    "        print('  ' + model + ' has roc_auc average: ' + str( sum(roc_scores[model]) / len(roc_scores[model]) ))\n",
    "\n",
    "# Function to perform a list of models:\n",
    "def perform_models(classifiers, X_train, X_test, y_train, y_test, count):\n",
    "    string = ''\n",
    "    print(str(count) + ' interaction:\\n')\n",
    "    for classifier in classifiers:\n",
    "        # Creating key index in dict to save evaluation metrics value:\n",
    "\n",
    "        string += classifier.__class__.__name__\n",
    "\n",
    "        # Train:\n",
    "        classifier.fit(X_train, y_train)\n",
    "        \n",
    "        # Predicting values with model:\n",
    "        predicteds = classifier.predict(X_test)\n",
    "        \n",
    "        # Getting score metrics:\n",
    "        f1 = f1_score(y_test, predicteds)\n",
    "        roc = roc_auc_score(y_test, predicteds, average='weighted')\n",
    "        \n",
    "        # Adding scores:\n",
    "        f1_scores[classifier.__class__.__name__].append(f1)\n",
    "        roc_scores[classifier.__class__.__name__].append(roc)\n",
    "\n",
    "        string += ' has f1: ' + str(f1) + ' roc_auc: ' + str(roc)+ '\\n'\n",
    "        print('    ' + string)\n",
    "        string = ''\n",
    "    print('-----------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'm going to create f1_scores and roc_scores dictionaries and call evaluate_models function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 interaction:\n",
      "\n",
      "    MLPClassifier has f1: 0.8057553956834532 roc_auc: 0.8782728622285454\n",
      "\n",
      "    RandomForestClassifier has f1: 0.849624060150376 roc_auc: 0.8817274467151365\n",
      "\n",
      "----------------------------------------------\n",
      "2 interaction:\n",
      "\n",
      "    MLPClassifier has f1: 0.8461538461538461 roc_auc: 0.9086841296422749\n",
      "\n",
      "    RandomForestClassifier has f1: 0.8654545454545455 roc_auc: 0.9019801309604346\n",
      "\n",
      "----------------------------------------------\n",
      "3 interaction:\n",
      "\n",
      "    MLPClassifier has f1: 0.8175182481751826 roc_auc: 0.8782963102618417\n",
      "\n",
      "    RandomForestClassifier has f1: 0.8602941176470589 roc_auc: 0.8952292362120018\n",
      "\n",
      "----------------------------------------------\n",
      "4 interaction:\n",
      "\n",
      "    MLPClassifier has f1: 0.8382352941176471 roc_auc: 0.8850765150518946\n",
      "\n",
      "    RandomForestClassifier has f1: 0.8602941176470589 roc_auc: 0.8952292362120018\n",
      "\n",
      "----------------------------------------------\n",
      "5 interaction:\n",
      "\n",
      "    MLPClassifier has f1: 0.8059701492537312 roc_auc: 0.8647945207649763\n",
      "\n",
      "    RandomForestClassifier has f1: 0.8178438661710038 roc_auc: 0.8715571395300571\n",
      "\n",
      "----------------------------------------------\n",
      "Results:\n",
      "MLPClassifier has f1 average: 0.822726586676772\n",
      "MLPClassifier has roc_auc average: 0.8830248675899066\n",
      "RandomForestClassifier has f1 average: 0.8507021414140086\n",
      "RandomForestClassifier has roc_auc average: 0.8891446379259262\n"
     ]
    }
   ],
   "source": [
    "f1_scores = {}\n",
    "roc_scores = {}\n",
    "\n",
    "evaluate_models(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling (with under-sampling):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation of results and predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
